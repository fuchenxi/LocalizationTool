#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""è¯Šæ–­å¯¼å‡ºé—®é¢˜ - å¯¹æ¯”åŸå§‹æ–‡ä»¶å’Œå¯¼å‡ºæ–‡ä»¶"""

import sys
import os
import re

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from models import LocalizationParser

def count_keyvalues_raw(file_path):
    """ç›´æ¥ç”¨æ­£åˆ™ç»Ÿè®¡åŸå§‹æ–‡ä»¶ä¸­çš„ key-value å¯¹æ•°é‡"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç§»é™¤æ³¨é‡Š
    content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
    content = re.sub(r'//.*?$', '', content, flags=re.MULTILINE)
    
    # ç»Ÿè®¡åŒ…å« = å’Œ ; çš„è¡Œï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
    pattern = r'"[^"]*"\s*=\s*"[^"]*"\s*;'
    simple_matches = re.findall(pattern, content)
    
    # ç»Ÿè®¡æ”¯æŒè½¬ä¹‰çš„å®Œæ•´æ¨¡å¼
    pattern_full = r'"((?:[^"\\]|\\.)*)"\s*=\s*"((?:[^"\\]|\\.)*)"\s*;'
    full_matches = re.findall(pattern_full, content, re.DOTALL)
    
    return len(simple_matches), len(full_matches)

print("=" * 70)
print("è¯Šæ–­å¯¼å‡ºé—®é¢˜")
print("=" * 70)

# 1. è®©ç”¨æˆ·è¾“å…¥åŸå§‹é¡¹ç›®è·¯å¾„
print("\nè¯·è¾“å…¥åŸå§‹é¡¹ç›®ä¸­çš„æŸä¸ª Localizable.strings æ–‡ä»¶è·¯å¾„ï¼š")
print("(ä¾‹å¦‚: /path/to/project/en.lproj/Localizable.strings)")
original_file = input().strip()

if not os.path.exists(original_file):
    print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {original_file}")
    sys.exit(1)

# 2. åˆ†æåŸå§‹æ–‡ä»¶
print(f"\nğŸ“„ åˆ†æåŸå§‹æ–‡ä»¶: {os.path.basename(original_file)}")
print("-" * 70)

with open(original_file, 'r', encoding='utf-8') as f:
    lines = f.readlines()

total_lines = len(lines)
non_empty = sum(1 for line in lines if line.strip())

print(f"æ€»è¡Œæ•°: {total_lines}")
print(f"éç©ºè¡Œ: {non_empty}")

simple_count, full_count = count_keyvalues_raw(original_file)
print(f"ç®€å•æ¨¡å¼åŒ¹é…åˆ°: {simple_count} ä¸ª key-value å¯¹")
print(f"å®Œæ•´æ¨¡å¼åŒ¹é…åˆ°: {full_count} ä¸ª key-value å¯¹")

# 3. ä½¿ç”¨è§£æå™¨è§£æ
parsed_data = LocalizationParser.parse_strings_file(original_file)
print(f"è§£æå™¨è§£æåˆ°: {len(parsed_data)} ä¸ª key-value å¯¹")

# 4. å¯¹æ¯”å·®å¼‚
print("\n" + "=" * 70)
if len(parsed_data) == full_count:
    print("âœ… è§£ææ­£å¸¸ï¼å¯¼å‡ºåº”è¯¥åŒ…å«æ‰€æœ‰å­—æ®µã€‚")
elif len(parsed_data) < full_count:
    diff = full_count - len(parsed_data)
    print(f"âš ï¸  ç¼ºå¤± {diff} ä¸ª key-value å¯¹ï¼")
    print("\nå¯èƒ½åŸå› ï¼š")
    print("  1. æŸäº›è¡Œæ ¼å¼ä¸æ ‡å‡†")
    print("  2. å­˜åœ¨ç‰¹æ®Šçš„è½¬ä¹‰åºåˆ—")
    print("  3. å¤šè¡Œ value å¤„ç†æœ‰é—®é¢˜")
    
    # æ˜¾ç¤ºä¸€äº›æ ·æœ¬
    print("\næ˜¾ç¤ºå‰5ä¸ªæˆåŠŸè§£æçš„ keyï¼š")
    for i, key in enumerate(list(parsed_data.keys())[:5]):
        print(f"  {i+1}. {key}")
else:
    print("âš ï¸  è§£ææ•°é‡å¤§äºé¢„æœŸï¼Œå¯èƒ½æœ‰é‡å¤")

# 5. æ£€æŸ¥å¯¼å‡ºæ–‡ä»¶
print("\n" + "=" * 70)
print("å¦‚æœä½ å·²ç»å¯¼å‡ºï¼Œè¯·è¾“å…¥å¯¼å‡ºçš„ .strings æ–‡ä»¶è·¯å¾„")
print("(ä¾‹å¦‚: ~/Desktop/LocalizationExport_xxx/Strings/en.strings)")
print("ç›´æ¥å›è½¦è·³è¿‡: ")
exported_file = input().strip()

if exported_file and os.path.exists(exported_file):
    exported_data = LocalizationParser.parse_strings_file(exported_file)
    print(f"\nğŸ“¤ å¯¼å‡ºæ–‡ä»¶åŒ…å«: {len(exported_data)} ä¸ª key-value å¯¹")
    
    if len(exported_data) == len(parsed_data):
        print("âœ… å¯¼å‡ºæ•°é‡åŒ¹é…ï¼")
    else:
        print(f"âš ï¸  å¯¼å‡ºæ•°é‡ä¸åŒ¹é…ï¼å·®å¼‚: {abs(len(exported_data) - len(parsed_data))}")

print("\n" + "=" * 70)
print("è¯Šæ–­å®Œæˆ")
print("=" * 70)

